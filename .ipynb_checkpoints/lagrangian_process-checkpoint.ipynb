{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d4efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca0658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_t is either a vector of the solution equation evaluated at all points t in [0,T] OR\n",
    "# a vector of the approximate solution values to y' = f(y;theta) at all points t in [0,T],\n",
    "# as calculated by our time integrator below\n",
    "# data is of form [(t,y_hat)], where y_hat is a data point collected at time t that should be compared against\n",
    "# y_n[index][1] for each data point as y[n] is of form [(t,y_i)] where y_i is an approx. sol\n",
    "def get_error(y_n,data):\n",
    "    error = 0\n",
    "    T = (y_n[-1][0]) # time T of final approximate solution\n",
    "    h = (y_n[1][0] - y_n[0][0]) # calculate timestep between each data point\n",
    "    n = int(T / h) # multiplier for each t to determine y_n index w/ data @ time t\n",
    "    print(f\"(n,T,h): ({n},{T},{h})\")\n",
    "    for index, (t,y_hat) in enumerate(data):\n",
    "        print(f\"data: ({t},{y_hat})\")\n",
    "        print(f\"approx (t,y_N):{y_n[n]}\") # (t,y_i)\n",
    "        error += (y_n[n*t][1] - y_hat) ** 2\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c05b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NUMPY VERSION OF EULER'S\n",
    "def forward_solve_euler_numpy(y_0,f,N,T,theta):\n",
    "    sols = np.zeros(N+1)\n",
    "    sols[0] = y_0\n",
    "    h = T/N # timestep length\n",
    "\n",
    "    # Calculate solutions\n",
    "    for i in range(N):\n",
    "        sols[i+1] = sols[i] + h * f(sols[i],theta)\n",
    "\n",
    "    return sols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4586b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LIST VERSION OF EULER'S\n",
    "def forward_solve_euler_list(y_0,f,N,T,theta):\n",
    "    y_ns = [(0,y_0)]\n",
    "    h = T/N # timestep length\n",
    "    t = h\n",
    "    \n",
    "    # Calculate solutions\n",
    "    for i in range(N):\n",
    "        new_y_i = y_ns[i][1] + h * f(y_ns[i][1],theta)\n",
    "        y_ns.append((t,new_y_i))\n",
    "        t += h\n",
    "    #print('y_ns in euler',y_ns)\n",
    "    return y_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069d6512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is of form [(t,y_hat)]\n",
    "# y_n is of form [(t,y_i)] where y_i is an approx. sol\n",
    "# f_partial_y is the partial derivative of the function f w.r.t. y\n",
    "def backward_solve_adjoint(data, y_ns, h, f_partial_y, theta):\n",
    "    y_hat = data[0][1]\n",
    "    #print('y_ns in adjoint',y_ns)\n",
    "    y_N = y_ns[-1] # use last y_n as y_N to compute lambda_N\n",
    "    #lambda_n = 2 * (y_hat - y_n[1]) ## Is this the correct derivative of the error to get the lambda_n terminal condition? Or the one on the below line?\n",
    "    lambda_N = 2 * (y_N[1] - y_hat) ## Uses error as (y_n - y_hat)^2 -> took derivative of this w.r.t. y_N\n",
    "    lambda_ns = [lambda_N] ## Initialize lambda list\n",
    "    y_nmin1_rev = y_ns[:-1][::-1]\n",
    "    for y_j in y_nmin1_rev:\n",
    "        # maybe could also grab all the f_partial_ys from here to use in the gradient to avoid recomputing?\n",
    "        new_lambda_j = lambda_ns[0] + (h * lambda_ns[0] * f_partial_y(theta,y_j)) # lambda_j+1 is first element of list\n",
    "        lambda_ns.insert(0,new_lambda_j) # put lambda_j at front of list\n",
    "    return lambda_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85818235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y[n] is of form [(t,y_j)] where y_j is an approx. sol\n",
    "# lambda_n is of form [lambda_j]\n",
    "# f_partial_theta is the partial derivative of the function f w.r.t. theta\n",
    "def L_partial_theta(lambda_n, h, f_partial_theta, y_ns, theta):\n",
    "    grad = 0\n",
    "    grad_lambdas = lambda_n[1:]\n",
    "    grad_y_ns = y_ns[:-1]\n",
    "    N_min_1 = len(grad_y_ns)\n",
    "    for j in range(N_min_1):\n",
    "        lambda_j = grad_lambdas[j]\n",
    "        f_partial_theta_y_j_min_1 = f_partial_theta(theta, grad_y_ns[j][1])\n",
    "        grad += lambda_j * h * f_partial_theta_y_j_min_1\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aac0c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(theta_init, M, alpha, data, y_0, f, f_partial_y, f_partial_theta, T, N):\n",
    "    theta_i = theta_init\n",
    "    gradient = 0\n",
    "    for i in range(M):\n",
    "        gradient = get_lagrange_gradient(theta_i, data, y_0, f, f_partial_y, f_partial_theta, T, N)\n",
    "        theta_i = theta_i + (alpha * -1 * gradient)\n",
    "    return theta_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b967c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lagrange_gradient(theta, data, y_0, f, f_partial_y, f_partial_theta, T, N):\n",
    "    y_ns = forward_solve_euler_list(y_0,f,N,T,theta) ## Forward solve for y_ns\n",
    "    #print('y_ns',y_ns)\n",
    "    lambda_ns = backward_solve_adjoint(data, y_ns, h, f_partial_y, theta) ## Backward solve for lambda_ns\n",
    "    #print('lambda_ns',lambda_ns)\n",
    "    grad = L_partial_theta(lambda_ns, h, f_partial_theta, y_ns, theta) ## Computed gradient with y_ns, lambda_ns\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce543d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_formula(y_0,f,N,T,theta,n):\n",
    "    return (1 + (theta)/N) ** n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7c180fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_formula():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4330993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_of_y_ex(theta,y):\n",
    "    return theta * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c083cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_partial_y_ex(theta,y):\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e14eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_partial_theta_ex(theta,y):\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63fd743f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n,T,h): (100,1.0000000000000007,0.01)\n",
      "data: (1,3)\n",
      "approx (t,y_N):(1.0000000000000007, 131.50125784630342)\n",
      "error 16512.573268082157\n"
     ]
    }
   ],
   "source": [
    "#### SET UP ODE\n",
    "theta_init = 5 # single parameter; should be generalized elsewhere\n",
    "f = f_of_y_ex\n",
    "y_prime = f\n",
    "y_0 = 1 ## data point @ t=0, or y(0)\n",
    "\n",
    "#### SET UP DATA\n",
    "data = [(1,3)]\n",
    "\n",
    "'''\n",
    "#### SET UP ACTUAL SOLUTION y(t)\n",
    "c = 1.5\n",
    "y = lambda y: c*y\n",
    "y_t = [y(1),y(2),y(3)]\n",
    "'''\n",
    "\n",
    "#### SET UP EULER TO OBTAIN APPROX SOL\n",
    "N = 100 ## Number of timesteps\n",
    "T = 1 ## set solution time interval as [0,T]\n",
    "h = T/N ## timestep length\n",
    "y_n = forward_solve_euler_list(y_0,f,N,T,theta_init) ## Get approx solution values at each time t in [0,T], where timestep length h is taken between each t\n",
    "\n",
    "euler_y_n = euler_formula(y_0,f,N,T,theta_init,N)\n",
    "#print('y_n approx of y:',y_n)\n",
    "\n",
    "len(y_n)\n",
    "\n",
    "error = get_error(y_n,data)\n",
    "print('error',error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb1c25bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lag_grad 32186.813412611522\n"
     ]
    }
   ],
   "source": [
    "lag_grad = get_lagrange_gradient(theta_init, data, y_0, f, f_partial_y_ex, f_partial_theta_ex, T, N)\n",
    "print('lag_grad',lag_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf5647be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1046692005503735\n"
     ]
    }
   ],
   "source": [
    "# theta_init defined\n",
    "M = 10000 # Number of iterations of gradient descent\n",
    "alpha = .0001 # learning constant\n",
    "# data defined above\n",
    "# y_0 defined above\n",
    "f = f_of_y_ex # f defined above but just redefining for completeness's sake\n",
    "f_partial_y = f_partial_y_ex\n",
    "f_partial_theta = f_partial_theta_ex\n",
    "# T defined above\n",
    "# N defined above\n",
    "optimal_theta = gradient_descent(theta_init, M, alpha, data, y_0, f, f_partial_y, f_partial_theta, T, N)\n",
    "print(optimal_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95099b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
